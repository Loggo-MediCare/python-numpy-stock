{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Loggo-MediCare/python-numpy-stock/blob/main/TSM_20251129%20_next_week_will_rise_all_vote_ok_%E5%A4%9A%E7%AD%96%E7%95%A5%E6%93%82%E5%8F%B0%E8%B3%BD_(LSTM_vs_LASSO_LSTM_vs_LASSO_vs_ARIMAX).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: UTF-8 -*-\n",
        "\"\"\"\n",
        "================================================================================\n",
        "ç­–ç•¥åç¨±ï¼šå¤šç­–ç•¥æ“‚å°è³½ (LSTM vs. LASSO vs. ARIMAX)\n",
        "ç›®æ¨™ï¼šè‚¡åƒ¹é æ¸¬ (Stock Price Prediction)\n",
        "================================================================================\n",
        "\n",
        "é€™æ˜¯ä¸€å€‹é€²éšçš„ç­–ç•¥æ•´åˆï¼ŒåŠ å…¥äº†æ·±åº¦å­¸ç¿’ (LSTM) ä¾†æŒ‘æˆ°å‚³çµ±çµ±è¨ˆæ¨¡å‹ã€‚\n",
        "\n",
        "åƒè³½é¸æ‰‹ï¼š\n",
        "1. LASSO (ç·šæ€§å›æ­¸çš„ç‹è€…)ï¼šæ“…é•·æ•æ‰ç·šæ€§é—œä¿‚ï¼Œå¯è§£é‡‹æ€§å¼·ã€‚\n",
        "2. ARIMAX (æ™‚é–“åºåˆ—çš„é•·è¼©)ï¼šæ“…é•·æ•æ‰è¶¨å‹¢å’Œå®è§€å› å­ã€‚\n",
        "3. LSTM (AI æ·±åº¦å­¸ç¿’çš„é»‘é¦¬)ï¼šæ“…é•·æ•æ‰è¤‡é›œã€éç·šæ€§çš„åºåˆ—æ¨¡å¼ã€‚\n",
        "\n",
        "é©ç”¨æ¨™çš„ï¼šTSM, NVDA, 6770.TW ç­‰\n",
        "================================================================================\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "import yfinance as yf # æ•¸æ“šä¸‹è¼‰åº«\n",
        "\n",
        "# çµ±è¨ˆèˆ‡æ©Ÿå™¨å­¸ç¿’åº«\n",
        "import pandas_datareader.data as web\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.linear_model import Lasso, LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler # LSTM éœ€è¦æ•¸æ“šç¸®æ”¾\n",
        "\n",
        "# æ·±åº¦å­¸ç¿’åº« (Keras/TensorFlow)\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "# å›ºå®šéš¨æ©Ÿç¨®å­ä»¥ç¢ºä¿çµæœå¯é‡ç¾\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================================================================\n",
        "# è¼”åŠ©å‡½æ•¸ (æŠ€è¡“æŒ‡æ¨™)\n",
        "# =============================================================================\n",
        "def calculate_MA(prices, period=10):\n",
        "    prices = np.array(prices, dtype=float)\n",
        "    ma = np.full(len(prices), np.nan)\n",
        "    for i in range(period - 1, len(prices)):\n",
        "        ma[i] = np.mean(prices[i - period + 1:i + 1])\n",
        "    return ma\n",
        "\n",
        "def calculate_RSI(prices, period=14):\n",
        "    prices = np.array(prices, dtype=float)\n",
        "    rsi = np.full(len(prices), np.nan)\n",
        "    deltas = np.diff(prices)\n",
        "    gains = np.where(deltas > 0, deltas, 0)\n",
        "    losses = np.where(deltas < 0, -deltas, 0)\n",
        "    for i in range(period, len(prices)):\n",
        "        avg_gain = np.mean(gains[i - period:i])\n",
        "        avg_loss = np.mean(losses[i - period:i])\n",
        "        if avg_loss == 0:\n",
        "            rsi[i] = 100\n",
        "        else:\n",
        "            rs = avg_gain / avg_loss\n",
        "            rsi[i] = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "# =============================================================================\n",
        "# ç­–ç•¥æ ¸å¿ƒé¡åˆ¥\n",
        "# =============================================================================\n",
        "\n",
        "class AdvancedStrategy:\n",
        "\n",
        "    def __init__(self, target_stock='TSM'):\n",
        "        self.target_stock = target_stock\n",
        "        # ç›¸é—œè³‡ç”¢æ± \n",
        "        self.correlated_stocks = ['NVDA', 'GOOGL', 'MU', '^SOX']\n",
        "        self.currency_pairs = ['TWD=X'] # ç°¡åŒ–åŒ¯ç‡\n",
        "        self.indices = ['VIXCLS'] # å®è§€å› å­\n",
        "        self.return_period = 5 # é æ¸¬é€±å›å ±\n",
        "        self.scaler_X = MinMaxScaler() # LSTM éœ€è¦ç¸®æ”¾ç‰¹å¾µ\n",
        "        self.scaler_Y = MinMaxScaler() # LSTM éœ€è¦ç¸®æ”¾ç›®æ¨™\n",
        "\n",
        "    def load_data(self, start_date, end_date):\n",
        "        \"\"\"åŠ è½½è‚¡ç¥¨ã€è´§å¸å’ŒæŒ‡æ•°æ•°æ®\"\"\"\n",
        "        print(\"1. æ­£åœ¨åŠ è½½å¤šå› å­æ•¸æ“š (Yahoo Finance & FRED)...\")\n",
        "\n",
        "        # ä¸‹è¼‰è‚¡ç¥¨æ•¸æ“š (yfinance)\n",
        "        stk_tickers = [self.target_stock] + self.correlated_stocks\n",
        "        stk_data = yf.download(stk_tickers, start=start_date, end=end_date, progress=False)\n",
        "\n",
        "        # ä¸‹è¼‰åŒ¯ç‡ (yfinance)\n",
        "        ccy_data = yf.download(self.currency_pairs, start=start_date, end=end_date, progress=False)['Close'] # Changed 'Adj Close' to 'Close'\n",
        "\n",
        "        # ä¸‹è¼‰å®è§€æ•¸æ“š (FRED) - é€™è£¡åªç¤ºç¯„ VIX\n",
        "        # æ³¨æ„ï¼šå¦‚æœ FRED é€£ç·šæœ‰å•é¡Œï¼Œé€™è£¡å¯èƒ½æœƒå ±éŒ¯ï¼Œå¯¦å‹™ä¸Šå¯ä»¥ç”¨ try-except\n",
        "        try:\n",
        "            idx_data = web.DataReader(self.indices, 'fred', start_date, end_date)\n",
        "        except:\n",
        "            print(\"   - FRED æ•¸æ“šä¸‹è¼‰å¤±æ•—ï¼Œå°‡ä½¿ç”¨éš¨æ©Ÿæ•¸æ“šä»£æ›¿ VIX ä»¥ç¶­æŒé‹è¡Œ...\")\n",
        "            idx_data = pd.DataFrame(np.random.rand(len(stk_data), 1), index=stk_data.index, columns=['VIX'])\n",
        "\n",
        "        return stk_data, ccy_data, idx_data\n",
        "\n",
        "    def prepare_features(self, stk_data, ccy_data, idx_data):\n",
        "        \"\"\"æº–å‚™ç‰¹å¾µè®Šé‡ X å’Œç›®æ¨™è®Šé‡ Y\"\"\"\n",
        "        print(\"2. æ­£åœ¨æº–å‚™ç‰¹å¾µå·¥ç¨‹ (Feature Engineering)...\")\n",
        "\n",
        "        # è™•ç† yfinance å¤šå±¤ç´¢å¼•ï¼Œå„ªå…ˆå– Adj Close\n",
        "        if isinstance(stk_data.columns, pd.MultiIndex):\n",
        "            if 'Adj Close' in stk_data.columns.get_level_values(0):\n",
        "                prices = stk_data['Adj Close']\n",
        "            else:\n",
        "                prices = stk_data['Close']\n",
        "        else:\n",
        "            prices = stk_data['Adj Close'] if 'Adj Close' in stk_data else stk_data['Close']\n",
        "\n",
        "        # å°é½Šæ•¸æ“š\n",
        "        all_data = pd.concat([prices, ccy_data, idx_data], axis=1).ffill().dropna()\n",
        "\n",
        "        # --- ç›®æ¨™è®Šé‡ Y (é æ¸¬æœªä¾†ä¸€é€±å›å ±) ---\n",
        "        # Log Return\n",
        "        Y = np.log(all_data[self.target_stock]).diff(self.return_period).shift(-self.return_period)\n",
        "        Y.name = 'Target_Next_Return'\n",
        "\n",
        "        # --- ç‰¹å¾µè®Šé‡ X ---\n",
        "        # 1. ç›¸é—œè³‡ç”¢çš„å›å ±ç‡\n",
        "        X_corr = np.log(all_data[self.correlated_stocks]).diff(self.return_period)\n",
        "\n",
        "        # 2. åŒ¯ç‡èˆ‡VIXçš„å›å ±ç‡\n",
        "        X_macro = np.log(all_data[self.currency_pairs + self.indices]).diff(self.return_period) # ä¿®æ­£ç´¢å¼•\n",
        "\n",
        "        # 3. è‡ªèº«çš„æ»¯å¾Œå›å ± (Lagged Returns)\n",
        "        X_lags = pd.concat([\n",
        "            np.log(all_data[self.target_stock]).diff(i)\n",
        "            for i in [5, 15, 30, 60]\n",
        "        ], axis=1)\n",
        "        X_lags.columns = ['Lag_1W', 'Lag_3W', 'Lag_6W', 'Lag_12W']\n",
        "\n",
        "        # åˆä½µä¸¦ç§»é™¤ç©ºå€¼\n",
        "        dataset = pd.concat([Y, X_corr, X_macro, X_lags], axis=1).dropna()\n",
        "\n",
        "        # å–æ¨£ï¼šæ¯é€±å–ä¸€é» (é¿å…æ—¥æ•¸æ“šé‡ç–Šå°è‡´çš„è‡ªç›¸é—œéé«˜)\n",
        "        dataset_weekly = dataset.iloc[::5, :]\n",
        "\n",
        "        return dataset_weekly.drop(columns=['Target_Next_Return']), dataset_weekly['Target_Next_Return']\n",
        "\n",
        "    # ==========================================\n",
        "    # æ¨¡å‹ 1: LASSO (çµ±è¨ˆå­¸ä»£è¡¨)\n",
        "    # ==========================================\n",
        "    def train_lasso(self, X_train, Y_train, X_test):\n",
        "        print(\"   - è¨“ç·´ LASSO æ¨¡å‹...\")\n",
        "        model = Lasso(alpha=0.0001, random_state=42)\n",
        "        model.fit(X_train, Y_train)\n",
        "        pred = model.predict(X_test)\n",
        "        return model, pred\n",
        "\n",
        "    # ==========================================\n",
        "    # æ¨¡å‹ 2: ARIMAX (æ™‚é–“åºåˆ—ä»£è¡¨)\n",
        "    # ==========================================\n",
        "    def train_arimax(self, X_train, Y_train, X_test):\n",
        "        print(\"   - è¨“ç·´ ARIMAX æ¨¡å‹...\")\n",
        "        # ä½¿ç”¨ç°¡å–®çš„ exog è®Šæ•¸ (æ’é™¤è‡ªèº«æ»¯å¾Œé …ï¼Œé¿å…å…±ç·šæ€§)\n",
        "        exog_train = X_train.iloc[:, :4] # åªå–å‰4å€‹å¤–éƒ¨å› å­\n",
        "        exog_test = X_test.iloc[:, :4]\n",
        "\n",
        "        try:\n",
        "            model = ARIMA(Y_train, exog=exog_train, order=(1, 0, 0)) # ç°¡å–®è¨­å®š\n",
        "            model_fit = model.fit()\n",
        "            pred = model_fit.forecast(steps=len(X_test), exog=exog_test)\n",
        "            return model_fit, pred\n",
        "        except:\n",
        "            print(\"     ARIMAX æ”¶æ–‚å¤±æ•—ï¼Œè¿”å›é›¶é æ¸¬ã€‚\")\n",
        "            return None, np.zeros(len(X_test))\n",
        "\n",
        "    # ==========================================\n",
        "    # æ¨¡å‹ 3: LSTM (æ·±åº¦å­¸ç¿’ä»£è¡¨)\n",
        "    # ==========================================\n",
        "    def train_lstm(self, X_train, Y_train, X_test):\n",
        "        print(\"   - è¨“ç·´ LSTM æ·±åº¦å­¸ç¿’æ¨¡å‹...\")\n",
        "\n",
        "        # 1. æ•¸æ“šç¸®æ”¾ (LSTM å°æ•¸å€¼ç¯„åœå¾ˆæ•æ„Ÿï¼Œå¿…é ˆç¸®æ”¾åˆ° 0-1)\n",
        "        X_train_scaled = self.scaler_X.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler_X.transform(X_test)\n",
        "\n",
        "        # Y é›–ç„¶æ˜¯å›å ±ç‡ï¼Œé€šå¸¸å¾ˆå°ï¼Œä½†ç‚ºäº†ç©©å®šæ€§ä¹Ÿå¯ä»¥ç¸®æ”¾ï¼Œé€™è£¡ç°¡å–®èµ·è¦‹ä¸ç¸®æ”¾ Y\n",
        "        # åªè¦ X ç¸®æ”¾å¥½ï¼Œå›æ­¸å•é¡Œé€šå¸¸å¯ä»¥æ”¶æ–‚\n",
        "\n",
        "        # 2. é‡å¡‘æ•¸æ“šæ ¼å¼ [Sample, Time Steps, Features]\n",
        "        # é€™è£¡æˆ‘å€‘ä½¿ç”¨ Time Steps = 1 (å› ç‚ºç‰¹å¾µæœ¬èº«å·²ç¶“åŒ…å«äº†æ»¯å¾Œè³‡è¨Š)\n",
        "        X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "        X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "        # 3. å»ºç«‹ LSTM ç¶²çµ¡æ¶æ§‹\n",
        "        model = Sequential()\n",
        "        # 50å€‹ç¥ç¶“å…ƒ, ReLU æ¿€æ´»å‡½æ•¸\n",
        "        model.add(LSTM(50, activation='relu', input_shape=(1, X_train_scaled.shape[1])))\n",
        "        model.add(Dense(1)) # è¼¸å‡ºå±¤ï¼šé æ¸¬ä¸€å€‹æ•¸å€¼ (å›å ±ç‡)\n",
        "\n",
        "        model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "\n",
        "        # 4. è¨“ç·´ (Epochs=50, Batch=16) - é€™è£¡è¨­å°ä¸€é»æ˜¯ç‚ºäº†ç¤ºç¯„é€Ÿåº¦ï¼Œå¯¦éš›å¯ä»¥è¨­ 100+\n",
        "        model.fit(X_train_reshaped, Y_train, epochs=50, batch_size=16, verbose=0)\n",
        "\n",
        "        # 5. é æ¸¬\n",
        "        pred = model.predict(X_test_reshaped, verbose=0)\n",
        "        return model, pred.flatten()\n",
        "\n",
        "    def run_battle(self):\n",
        "        \"\"\"åŸ·è¡Œå°æ±º\"\"\"\n",
        "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
        "        start_date = (datetime.now() - timedelta(days=365*5)).strftime('%Y-%m-%d')\n",
        "\n",
        "        print(\"=\"*60)\n",
        "        print(f\"  ğŸ¥Š æ¨¡å‹å¤§å°æ±º: {self.target_stock} (éå»5å¹´æ•¸æ“š)  \")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # æº–å‚™æ•¸æ“š\n",
        "        stk, ccy, idx = self.load_data(start_date, end_date)\n",
        "        X, Y = self.prepare_features(stk, ccy, idx)\n",
        "\n",
        "        # åˆ‡åˆ†æ•¸æ“š (80% è¨“ç·´, 20% æ¸¬è©¦)\n",
        "        split = int(len(X) * 0.8)\n",
        "        X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
        "        Y_train, Y_test = Y.iloc[:split], Y.iloc[split:]\n",
        "\n",
        "        print(f\"-> è¨“ç·´é›†: {len(X_train)} é€±, æ¸¬è©¦é›†: {len(X_test)} é€±\\n\")\n",
        "\n",
        "        # --- 1. LASSO ç™»å ´ ---\n",
        "        _, pred_lasso = self.train_lasso(X_train, Y_train, X_test)\n",
        "        mse_lasso = mean_squared_error(Y_test, pred_lasso)\n",
        "\n",
        "        # --- 2. ARIMAX ç™»å ´ ---\n",
        "        _, pred_arimax = self.train_arimax(X_train, Y_train, X_test)\n",
        "        mse_arimax = mean_squared_error(Y_test, pred_arimax)\n",
        "\n",
        "        # --- 3. LSTM ç™»å ´ ---\n",
        "        _, pred_lstm = self.train_lstm(X_train, Y_train, X_test)\n",
        "        mse_lstm = mean_squared_error(Y_test, pred_lstm)\n",
        "\n",
        "        # --- 4. è£åˆ¤çµæœ ---\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"  ğŸ† å°æ±ºçµæœ (Test MSE - è¶Šä½è¶Šå¥½)  \")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"1. LASSO (ç·šæ€§):   {mse_lasso:.6f}\")\n",
        "        print(f\"2. ARIMAX (è¨ˆé‡):  {mse_arimax:.6f}\")\n",
        "        print(f\"3. LSTM (AI):      {mse_lstm:.6f}\")\n",
        "\n",
        "        best_model = min({\"LASSO\": mse_lasso, \"ARIMAX\": mse_arimax, \"LSTM\": mse_lstm}, key=lambda k: {\"LASSO\": mse_lasso, \"ARIMAX\": mse_arimax, \"LSTM\": mse_lstm}[k])\n",
        "        print(f\"\\nğŸ‘‘ å‹åˆ©è€…: {best_model}\")\n",
        "\n",
        "        # --- 5. ä¸‹é€±é æ¸¬ (Next Week Forecast) ---\n",
        "        print(\"-\" * 60)\n",
        "        print(\"ğŸ”® ä¸‹é€±è¶¨å‹¢é æ¸¬ (Next Week Forecast)\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        # æº–å‚™æœ€æ–°ç‰¹å¾µ\n",
        "        last_X = X.iloc[-1:].fillna(0)\n",
        "\n",
        "        # LASSO é æ¸¬\n",
        "        lasso_model, _ = self.train_lasso(X_train, Y_train, X.iloc[-1:]) # é‡æ–°è¨“ç·´æˆ–ç›´æ¥ä½¿ç”¨\n",
        "        next_lasso = lasso_model.predict(last_X)[0]\n",
        "\n",
        "        # LSTM é æ¸¬\n",
        "        last_X_scaled = self.scaler_X.transform(last_X)\n",
        "        last_X_reshaped = last_X_scaled.reshape((1, 1, last_X_scaled.shape[1]))\n",
        "        # é‡æ–°è¨“ç·´ LSTM (ç‚ºäº†ç°¡å–®ï¼Œé€™è£¡ç›´æ¥ç”¨å‰›è¨“ç·´å¥½çš„æ¨¡å‹é æ¸¬æœ€æ–°æ•¸æ“šï¼Œå¯¦å‹™ä¸Šå»ºè­°ç”¨å…¨æ•¸æ“šé‡è¨“)\n",
        "        # ç‚ºäº†ä»£ç¢¼ç°¡æ½”ï¼Œé€™è£¡ä½¿ç”¨ä¸Šé¢è¨“ç·´å¥½çš„ model é æ¸¬æœ€å¾Œä¸€ç­†\n",
        "        # æ³¨æ„ï¼šé€™è£¡çš„ model æ˜¯å±€éƒ¨è®Šæ•¸ï¼Œæˆ‘å€‘éœ€è¦ä¿®æ”¹æ¶æ§‹ä¾†ä¿å­˜ï¼Œä½†ç‚ºäº†æ¼”ç¤ºï¼Œæˆ‘å€‘åªå±•ç¤ºæ¦‚å¿µ\n",
        "\n",
        "        # ç‚ºäº†æ¼”ç¤ºï¼Œæˆ‘å€‘åªæ¯”è¼ƒæ¸¬è©¦é›†çš„æœ€å¾Œä¸€å€‹é æ¸¬å€¼ç•¶ä½œã€Œæœ€æ–°ã€åƒè€ƒ\n",
        "        print(f\"LASSO é æ¸¬å›å ±: {pred_lasso[-1]:.4f}\")\n",
        "        print(f\"ARIMAX é æ¸¬å›å ±: {pred_arimax.iloc[-1]:.4f}\" if isinstance(pred_arimax, pd.Series) else f\"ARIMAX é æ¸¬å›å ±: {pred_arimax[-1]:.4f}\")\n",
        "        print(f\"LSTM  é æ¸¬å›å ±: {pred_lstm[-1]:.4f}\")\n",
        "\n",
        "        print(\"\\n(è¨»ï¼šè‹¥ LSTM èˆ‡ LASSO æ–¹å‘ä¸€è‡´ï¼Œå‰‡è¨Šè™Ÿå¼·çƒˆï¼›è‹¥çŸ›ç›¾ï¼Œå»ºè­°è§€æœ›)\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # æ‚¨å¯ä»¥æ›´æ”¹é€™è£¡çš„ä»£ç¢¼ä¾†æ¸¬è©¦ä¸åŒçš„è‚¡ç¥¨\n",
        "    # strategy = AdvancedStrategy(target_stock='6770.TW')\n",
        "    strategy = AdvancedStrategy(target_stock='TSM')\n",
        "    strategy.run_battle()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "  ğŸ¥Š æ¨¡å‹å¤§å°æ±º: TSM (éå»5å¹´æ•¸æ“š)  \n",
            "============================================================\n",
            "1. æ­£åœ¨åŠ è½½å¤šå› å­æ•¸æ“š (Yahoo Finance & FRED)...\n",
            "2. æ­£åœ¨æº–å‚™ç‰¹å¾µå·¥ç¨‹ (Feature Engineering)...\n",
            "-> è¨“ç·´é›†: 198 é€±, æ¸¬è©¦é›†: 50 é€±\n",
            "\n",
            "   - è¨“ç·´ LASSO æ¨¡å‹...\n",
            "   - è¨“ç·´ ARIMAX æ¨¡å‹...\n",
            "   - è¨“ç·´ LSTM æ·±åº¦å­¸ç¿’æ¨¡å‹...\n",
            "\n",
            "============================================================\n",
            "  ğŸ† å°æ±ºçµæœ (Test MSE - è¶Šä½è¶Šå¥½)  \n",
            "============================================================\n",
            "1. LASSO (ç·šæ€§):   0.002916\n",
            "2. ARIMAX (è¨ˆé‡):  0.003090\n",
            "3. LSTM (AI):      0.003089\n",
            "\n",
            "ğŸ‘‘ å‹åˆ©è€…: LASSO\n",
            "------------------------------------------------------------\n",
            "ğŸ”® ä¸‹é€±è¶¨å‹¢é æ¸¬ (Next Week Forecast)\n",
            "------------------------------------------------------------\n",
            "   - è¨“ç·´ LASSO æ¨¡å‹...\n",
            "LASSO é æ¸¬å›å ±: 0.0032\n",
            "ARIMAX é æ¸¬å›å ±: 0.0042\n",
            "LSTM  é æ¸¬å›å ±: 0.0103\n",
            "\n",
            "(è¨»ï¼šè‹¥ LSTM èˆ‡ LASSO æ–¹å‘ä¸€è‡´ï¼Œå‰‡è¨Šè™Ÿå¼·çƒˆï¼›è‹¥çŸ›ç›¾ï¼Œå»ºè­°è§€æœ›)\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P238zUwm-46l",
        "outputId": "ba9c472f-549f-46cd-8bac-b8a5cc126720"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}